# Copinance OS Environment Configuration
# Copy this file to .env and update with your values

# =============================================================================
# Application Settings
# =============================================================================
COPINANCEOS_APP_NAME=Copinance OS
COPINANCEOS_ENVIRONMENT=development

COPINANCEOS_STORAGE_TYPE=file
COPINANCEOS_STORAGE_PATH=.copinance

# Use memory storage (for testing)
COPINANCEOS_STORAGE_TYPE=memory

# =============================================================================
# Logging Configuration
# =============================================================================
# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
COPINANCEOS_LOG_LEVEL=INFO
# Log formats: json (for production) or console (for development)
COPINANCEOS_LOG_FORMAT=console

# =============================================================================
# Workflow Settings
# =============================================================================
COPINANCEOS_DEFAULT_WORKFLOW_TIMEOUT=300
COPINANCEOS_ENABLE_AGENTIC_WORKFLOWS=true

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Default LLM provider (used if no workflow-specific mapping is set)
# Options: gemini, ollama, openai, anthropic
COPINANCEOS_LLM_PROVIDER=gemini

# Default LLM parameters
COPINANCEOS_LLM_TEMPERATURE=0.7
COPINANCEOS_LLM_MAX_TOKENS=

# Per-workflow LLM provider mapping (optional)
# Format: workflow_type:provider_name,workflow_type:provider_name
# Example: static:ollama,agentic:gemini,fundamentals:gemini
# This allows different workflows to use different LLM providers
COPINANCEOS_WORKFLOW_LLM_PROVIDERS=

# =============================================================================
# Gemini (Google) Configuration
# =============================================================================
# Get your API key from: https://makersuite.google.com/app/apikey
COPINANCEOS_GEMINI_API_KEY=
COPINANCEOS_GEMINI_MODEL=gemini-pro

# =============================================================================
# OpenAI Configuration
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
COPINANCEOS_OPENAI_API_KEY=
COPINANCEOS_OPENAI_MODEL=gpt-4
# Optional: Custom base URL for OpenAI-compatible APIs or proxies
# COPINANCEOS_OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# Anthropic Configuration
# =============================================================================
# Get your API key from: https://console.anthropic.com/
COPINANCEOS_ANTHROPIC_API_KEY=
COPINANCEOS_ANTHROPIC_MODEL=claude-3-opus-20240229

# =============================================================================
# Ollama (Local LLM) Configuration
# =============================================================================
# Install Ollama from: https://ollama.ai
# Then pull a model: ollama pull llama2
# Install Copinance OS with Ollama support: pip install -e ".[ollama]"
COPINANCEOS_OLLAMA_BASE_URL=http://localhost:11434
COPINANCEOS_OLLAMA_MODEL=llama2
